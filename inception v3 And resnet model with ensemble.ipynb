{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c739c4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from imageio import imread\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import tf_slim as slim\n",
    "from tf_slim.nets import inception\n",
    "import tf_slim as slim\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aedee559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b19b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"inception_v3.ckpt\"\n",
    "images_path = \"dataset_splitted/train/*\"\n",
    "img_width = 299\n",
    "img_height = 299\n",
    "batch_size = 16\n",
    "batch_shape = [batch_size, img_height, img_width, 3]\n",
    "num_classes = 1001\n",
    "predict_output = []\n",
    "class_names_path = \"class_names.txt\"\n",
    "with open(class_names_path) as f:\n",
    "    class_names = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67cbdf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1455 images belonging to 30 classes.\n",
      "Found 380 images belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Set up data generators\n",
    "train_dir = 'dataset_splitted/train'\n",
    "test_dir = 'dataset_splitted/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125636a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46/46 [==============================] - 53s 1s/step - loss: 2.9975 - accuracy: 0.3045 - val_loss: 2.8920 - val_accuracy: 0.1895\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 48s 1s/step - loss: 0.9624 - accuracy: 0.7491 - val_loss: 2.7109 - val_accuracy: 0.2368\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 48s 1s/step - loss: 0.5763 - accuracy: 0.8302 - val_loss: 2.0333 - val_accuracy: 0.4132\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 51s 1s/step - loss: 0.4205 - accuracy: 0.8832 - val_loss: 2.3957 - val_accuracy: 0.3053\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 49s 1s/step - loss: 0.3045 - accuracy: 0.9155 - val_loss: 2.6334 - val_accuracy: 0.3263\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 48s 1s/step - loss: 0.2359 - accuracy: 0.9306 - val_loss: 2.5161 - val_accuracy: 0.4053\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 49s 1s/step - loss: 0.2409 - accuracy: 0.9299 - val_loss: 2.8943 - val_accuracy: 0.3184\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 48s 1s/step - loss: 0.1874 - accuracy: 0.9423 - val_loss: 4.3182 - val_accuracy: 0.2579\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 50s 1s/step - loss: 0.1834 - accuracy: 0.9443 - val_loss: 3.4182 - val_accuracy: 0.2658\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 51s 1s/step - loss: 0.1262 - accuracy: 0.9629 - val_loss: 2.2958 - val_accuracy: 0.4211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46/46 [==============================] - 123s 3s/step - loss: 0.0629 - accuracy: 0.9801 - val_loss: 1.2425 - val_accuracy: 0.6368\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 113s 2s/step - loss: 0.0451 - accuracy: 0.9863 - val_loss: 0.5005 - val_accuracy: 0.8211\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 120s 3s/step - loss: 0.0328 - accuracy: 0.9918 - val_loss: 0.2034 - val_accuracy: 0.9368\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 136s 3s/step - loss: 0.0230 - accuracy: 0.9952 - val_loss: 0.1170 - val_accuracy: 0.9658\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 112s 2s/step - loss: 0.0255 - accuracy: 0.9931 - val_loss: 0.0881 - val_accuracy: 0.9711\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 116s 3s/step - loss: 0.0163 - accuracy: 0.9973 - val_loss: 0.0682 - val_accuracy: 0.9763\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 117s 3s/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.0553 - val_accuracy: 0.9816\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 118s 3s/step - loss: 0.0151 - accuracy: 0.9979 - val_loss: 0.0545 - val_accuracy: 0.9816\n",
      "Epoch 9/10\n",
      "20/46 [============>.................] - ETA: 1:02 - loss: 0.0209 - accuracy: 0.9952"
     ]
    }
   ],
   "source": [
    " # Set up the model\n",
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "\tlayer.trainable = False\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=10, validation_data=test_generator)\n",
    "\n",
    " # Unfreeze the base model layers for fine-tuning\n",
    "for layer in base_model.layers:\n",
    "\tlayer.trainable = True\n",
    "\n",
    "# Re-compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "model.fit(train_generator, epochs=10, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd22515",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model_inception.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b632bb",
   "metadata": {},
   "source": [
    "# Second Model (after first model is saved restart the kernel then run second model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20dc03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "988fb844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "#dataset_url = \"https://drive.google.com/drive/folders/1cXFP4ECfzuaxMkjneZ5jzQbyKIXVKmvy?usp=share_link\"\n",
    "#data_dir = tf.keras.utils.get_file('Segmented Medicinal Leaf Images', origin=dataset_url, untar=True)\n",
    "#data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "data_dir = \"Segmented Medicinal Leaf Images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09ecd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1833 files belonging to 30 classes.\n",
      "Using 1467 files for training.\n"
     ]
    }
   ],
   "source": [
    "img_height_1,img_width_1=180,180\n",
    "batch_size_1=32\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height_1, img_width_1),\n",
    "  batch_size=batch_size_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14320a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1833 files belonging to 30 classes.\n",
      "Using 366 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height_1, img_width_1),\n",
    "  batch_size=batch_size_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7cb6dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alpinia Galanga (Rasna)', 'Amaranthus Viridis (Arive-Dantu)', 'Artocarpus Heterophyllus (Jackfruit)', 'Azadirachta Indica (Neem)', 'Basella Alba (Basale)', 'Brassica Juncea (Indian Mustard)', 'Carissa Carandas (Karanda)', 'Citrus Limon (Lemon)', 'Ficus Auriculata (Roxburgh fig)', 'Ficus Religiosa (Peepal Tree)', 'Hibiscus Rosa-sinensis', 'Jasminum (Jasmine)', 'Mangifera Indica (Mango)', 'Mentha (Mint)', 'Moringa Oleifera (Drumstick)', 'Muntingia Calabura (Jamaica Cherry-Gasagase)', 'Murraya Koenigii (Curry)', 'Nerium Oleander (Oleander)', 'Nyctanthes Arbor-tristis (Parijata)', 'Ocimum Tenuiflorum (Tulsi)', 'Piper Betle (Betel)', 'Plectranthus Amboinicus (Mexican Mint)', 'Pongamia Pinnata (Indian Beech)', 'Psidium Guajava (Guava)', 'Punica Granatum (Pomegranate)', 'Santalum Album (Sandalwood)', 'Syzygium Cumini (Jamun)', 'Syzygium Jambos (Rose Apple)', 'Tabernaemontana Divaricata (Crape Jasmine)', 'Trigonella Foenum-graecum (Fenugreek)']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e249fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_1 = ResNet50(weights='imagenet', include_top=False)\n",
    "y = base_model_1.output\n",
    "y= GlobalAveragePooling2D()(y)\n",
    "y= Dense(512, activation='relu')(y)\n",
    "predictions_1 = Dense(30, activation='softmax')(y)\n",
    "model_1 = tf.keras.Model(inputs=base_model_1.input, outputs=predictions_1)\n",
    "\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer_1 in base_model_1.layers:\n",
    "    layer_1.trainable = False\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_1.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9521b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('Model_resnet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a01783",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "578da134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:93: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:93: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:93: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 46 steps, validate on 12 steps\n",
      "Epoch 1/25\n",
      "46/46 [==============================] - ETA: 0s - batch: 22.5000 - size: 1.0000 - loss: 0.8692 - acc: 0.6087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 64s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.8692 - acc: 0.6087 - val_loss: 1.2841 - val_acc: 0.0219\n",
      "Epoch 2/25\n",
      "46/46 [==============================] - 56s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.5836 - acc: 0.6414 - val_loss: 1.1243 - val_acc: 0.0383\n",
      "Epoch 3/25\n",
      "46/46 [==============================] - 56s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.5182 - acc: 0.6789 - val_loss: 0.8948 - val_acc: 0.7951\n",
      "Epoch 4/25\n",
      "46/46 [==============================] - 56s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.5272 - acc: 0.6653 - val_loss: 0.9200 - val_acc: 0.3306\n",
      "Epoch 5/25\n",
      "46/46 [==============================] - 56s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.4554 - acc: 0.7389 - val_loss: 0.7954 - val_acc: 0.4071\n",
      "Epoch 6/25\n",
      "46/46 [==============================] - 58s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.4522 - acc: 0.6885 - val_loss: 0.8207 - val_acc: 0.1175\n",
      "Epoch 7/25\n",
      "46/46 [==============================] - 57s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.4672 - acc: 0.6960 - val_loss: 0.7822 - val_acc: 0.2705\n",
      "Epoch 8/25\n",
      "46/46 [==============================] - 55s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.4532 - acc: 0.7798 - val_loss: 0.8637 - val_acc: 0.1066\n",
      "Epoch 9/25\n",
      "46/46 [==============================] - 56s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.4274 - acc: 0.8160 - val_loss: 0.6433 - val_acc: 0.4672\n",
      "Epoch 10/25\n",
      "46/46 [==============================] - 57s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.4052 - acc: 0.8582 - val_loss: 0.6137 - val_acc: 0.5820\n",
      "Epoch 11/25\n",
      "46/46 [==============================] - 56s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.4144 - acc: 0.8275 - val_loss: 0.8436 - val_acc: 0.2213\n",
      "Epoch 12/25\n",
      "46/46 [==============================] - 55s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.4284 - acc: 0.7491 - val_loss: 0.6417 - val_acc: 0.5847\n",
      "Epoch 13/25\n",
      "46/46 [==============================] - 57s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.3950 - acc: 0.7607 - val_loss: 0.7260 - val_acc: 0.4973\n",
      "Epoch 14/25\n",
      "46/46 [==============================] - 56s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.4192 - acc: 0.7928 - val_loss: 0.8357 - val_acc: 0.2404\n",
      "Epoch 15/25\n",
      "46/46 [==============================] - 56s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.3701 - acc: 0.8718 - val_loss: 0.5918 - val_acc: 0.5792\n",
      "Epoch 16/25\n",
      "46/46 [==============================] - 55s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.3385 - acc: 0.8759 - val_loss: 0.5724 - val_acc: 0.5820\n",
      "Epoch 17/25\n",
      "46/46 [==============================] - 55s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.3232 - acc: 0.8384 - val_loss: 0.6801 - val_acc: 0.4809\n",
      "Epoch 18/25\n",
      "46/46 [==============================] - 56s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.3416 - acc: 0.8228 - val_loss: 0.7943 - val_acc: 0.2186\n",
      "Epoch 19/25\n",
      "46/46 [==============================] - 56s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.3784 - acc: 0.7805 - val_loss: 0.7932 - val_acc: 0.2705\n",
      "Epoch 20/25\n",
      "46/46 [==============================] - 57s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.4002 - acc: 0.7737 - val_loss: 0.7782 - val_acc: 0.2268\n",
      "Epoch 21/25\n",
      "46/46 [==============================] - 58s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.4078 - acc: 0.7798 - val_loss: 0.7022 - val_acc: 0.4672\n",
      "Epoch 22/25\n",
      "46/46 [==============================] - 55s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.3680 - acc: 0.8139 - val_loss: 0.7010 - val_acc: 0.5574\n",
      "Epoch 23/25\n",
      "46/46 [==============================] - 56s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.3272 - acc: 0.8296 - val_loss: 0.8833 - val_acc: 0.1448\n",
      "Epoch 24/25\n",
      "46/46 [==============================] - 56s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.3145 - acc: 0.8153 - val_loss: 0.5617 - val_acc: 0.5847\n",
      "Epoch 25/25\n",
      "46/46 [==============================] - 58s 1s/step - batch: 22.5000 - size: 1.0000 - loss: 0.3163 - acc: 0.8010 - val_loss: 0.7295 - val_acc: 0.3689\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "model_1 = load_model('Model_resnet.h5')\n",
    "model_1 = Model(inputs=model_1.inputs,\n",
    "                outputs=model_1.outputs,\n",
    "                name='Model_resnet')\n",
    "model_2 = load_model('Model_inception.h5')\n",
    "model_2 = Model(inputs=model_2.inputs,\n",
    "                outputs=model_2.outputs,\n",
    "                name='Model_inception')\n",
    "models = [model_1, model_2]\n",
    "model_input = Input(shape=(180, 180, 3))\n",
    "model_outputs = [model(model_input) for model in models]\n",
    "ensemble_output = Average()(model_outputs)\n",
    "ensemble_model = Model(inputs=model_input, outputs=ensemble_output, name='ensemble')\n",
    "\n",
    "ensemble_model.compile(optimizer='adam',loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=['accuracy'])\n",
    "\n",
    "history=ensemble_model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c503ccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 180, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image=cv2.imread(\"tulsi.jpeg\")\n",
    "image_resized= cv2.resize(image, (img_height_1,img_width_1))\n",
    "image=np.expand_dims(image_resized,axis=0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "660e11a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.0484809e-06 3.5874385e-03 1.3415996e-04 1.2422218e-03 1.6961672e-03\n",
      "  3.5385210e-03 1.0857991e-05 1.8202303e-06 9.2724241e-02 3.2798625e-06\n",
      "  2.7636934e-02 7.2447066e-05 2.2916652e-03 4.6880804e-03 3.9619558e-06\n",
      "  2.0973174e-02 4.8323353e-03 2.5755858e-07 1.5622465e-01 9.3866289e-02\n",
      "  2.9413623e-01 8.4818266e-03 4.8135128e-02 7.0602614e-03 1.6820153e-03\n",
      "  6.6715088e-03 3.4453596e-08 2.2022185e-01 2.3610066e-06 7.1278388e-05]]\n"
     ]
    }
   ],
   "source": [
    "pred=ensemble_model.predict(image)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dd80ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is Piper Betle (Betel)\n"
     ]
    }
   ],
   "source": [
    "output_class=class_names[np.argmax(pred)]\n",
    "print(\"The predicted class is\", output_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084c2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47012d3b",
   "metadata": {},
   "source": [
    "# Loading indivisual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "244864f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('Model_resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ff93c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 180, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image=cv2.imread(\"tulsi.jpeg\")\n",
    "image_resized= cv2.resize(image, (img_height_1,img_width_1))\n",
    "image=np.expand_dims(image_resized,axis=0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa06fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.33768878e-04 3.31925577e-03 9.56216827e-05 2.24959273e-02\n",
      "  7.82601722e-03 1.46321720e-02 1.00900834e-04 4.55371155e-05\n",
      "  3.82848233e-02 1.92941472e-04 3.21281441e-02 6.40214639e-05\n",
      "  1.10583911e-02 9.34171006e-02 5.49727656e-06 3.45358960e-02\n",
      "  6.59421599e-03 3.10778487e-05 8.74477327e-02 5.67650080e-01\n",
      "  3.18378326e-03 9.80196986e-03 2.00926187e-03 9.70660651e-04\n",
      "  1.89831760e-02 4.46591452e-02 1.87765927e-05 3.44677574e-05\n",
      "  3.45699409e-05 1.45069847e-04]]\n"
     ]
    }
   ],
   "source": [
    "pred=new_model.predict(image)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "281eb652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is Ocimum Tenuiflorum (Tulsi)\n"
     ]
    }
   ],
   "source": [
    "output_class=class_names[np.argmax(pred)]\n",
    "print(\"The predicted class is\", output_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5f93c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_1 = tf.keras.models.load_model('Model_inception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee102157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 180, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image=cv2.imread(\"tulsi.jpeg\")\n",
    "image_resized= cv2.resize(image, (img_height_1,img_width_1))\n",
    "image=np.expand_dims(image_resized,axis=0)\n",
    "print(image.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76a2632e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.33768878e-04 3.31925577e-03 9.56216827e-05 2.24959273e-02\n",
      "  7.82601722e-03 1.46321720e-02 1.00900834e-04 4.55371155e-05\n",
      "  3.82848233e-02 1.92941472e-04 3.21281441e-02 6.40214639e-05\n",
      "  1.10583911e-02 9.34171006e-02 5.49727656e-06 3.45358960e-02\n",
      "  6.59421599e-03 3.10778487e-05 8.74477327e-02 5.67650080e-01\n",
      "  3.18378326e-03 9.80196986e-03 2.00926187e-03 9.70660651e-04\n",
      "  1.89831760e-02 4.46591452e-02 1.87765927e-05 3.44677574e-05\n",
      "  3.45699409e-05 1.45069847e-04]]\n"
     ]
    }
   ],
   "source": [
    "pred=new_model.predict(image)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fee241a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is Ocimum Tenuiflorum (Tulsi)\n"
     ]
    }
   ],
   "source": [
    "output_class=class_names[np.argmax(pred)]\n",
    "print(\"The predicted class is\", output_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d27e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
